{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# By Vinayak Lal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine\n",
    "\n",
    "1. SVM offers very high accuracy compared to other classifiers such as KNN,and decision trees.\n",
    "2. Very good in handling non linear input spaces.\n",
    "3. Used in a variety of applications such as face detection,intrusion detection,classification of emails,news articles and webpages,classification of genes,and handwriting recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine Working \n",
    "1. Supervised Machine Learning algorithm\n",
    "2. Mostly used for classification\n",
    "3. Data is labeled (Classes are used like 0,1,2,3....)\n",
    "4. To seperate the 2 classes we draw a line/plane to distinguish the 2 classes\n",
    "5. 1 side will have 1 class and the other side has another class\n",
    "6. The line or plane is called Hyperplane.\n",
    "7. This line is called the decision boundry as it decides the new pointg lies on which side or class.\n",
    "8. We find out the point in Class 1 which is closest to the point in class 2 and vice versa and draw a line close to these ponits(just passing this points).\n",
    "9. These lines drawn are D- and D+ distances away from the Hyperplane and the total distance between these D- and D+ lines is called teh margin.\n",
    "10. The points that helped in making the margin is calle dteh support vectors.\n",
    "11. Many margins in different direction are calculated and the margin with the maximum width is taken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine Kernel (or Kernel Trick)\n",
    "1. When Data cannot be divided into 2 classes by simply drawing a straight plane -- this is called Non Linear SVM\n",
    "2. Kernel functon takes the low dimension feature space and converts to High Dimension feature space\n",
    "    - LOW DIMENSION --> KERNEL --> HIGH DIMENSION (1D to 2D ----- 2D to 3D)\n",
    "3. Linear Kernel --> When classes can be separated drwing a straight line/plane\n",
    "4. Polynomial Kernel --> A polynomial equation is made which fits the points and in turn a line/plane can be draw on the polynomial equation curve to separate the 2 classes\n",
    "5. RBF Kernel --> A wave function is created in increasing form \n",
    "6. Sigmoid Kernel --> a sigmoid wave is formed and a threshold is taken to draw the line to seperate the classes.\n",
    "![Types of SVM Kernel](kt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principle Component Analysis - PCA\n",
    "1. Unsupervised Machine Learning Algorithm\n",
    "2. Used to reduce the dimensions of data\n",
    "3. Reduce the dimensionaltiy of data\n",
    "4. 1000 features arereduced to a maximum usgae features (like 10 or 20)\n",
    "5. Transforms the features into less features\n",
    "6. Also used for feature selection.\n",
    "\n",
    "# Basic Statistics for PCA\n",
    "1. Statistics is the branch of mathematics\n",
    "2. Mean --> How data is centered?\n",
    "3. Median --> How data positions is centered?\n",
    "4. Mode --> What is the frequency of data values?\n",
    "5. Standard Deviation --> What is the range of data values?\n",
    "    - Difference between actual detsination and expected destination is DEVIATION\n",
    "    - Actual value is how far from mean of sample\n",
    "    - DEVIATION = x1 - x(mean), x2 - x(mean) ........ xn - x(mean)\n",
    "    - STANDARD DEVIATION = sqr root((x1 - x(mean))^2 + (x2 - x(mean))^2 + ........ + (xn - x(mean))^2) or avg(sqrroot((xn - x(mean))^2)\n",
    "6. Variance --> How data values varry with each other?\n",
    "    - VARIANCE = (STD DEV)^2\n",
    "\n",
    "# Correlation and Covariance for PCA\n",
    "1. Covariance:\n",
    "    - Between 2 variables/columns\n",
    "    - Also known as Joint Variability\n",
    "    - Values range between -inf to +inf\n",
    "    ![Covariance](cov.jpg)\n",
    "2. Correlation:\n",
    "    - Normalization of Covariance \n",
    "    - Converts the values to -1 to +1\n",
    "    - We divide the covariance by std dev of x and std dev of y\n",
    "    ![Correalation](cor.png)\n",
    "3. Covariance Matrix:\n",
    "    - [[Var(x) CoVar(xy) CoVar(xz)] [CoVar(yx) Var(y) CoVar(yz)] [CoVar(zx) CoVar(zy) Var(z)]]\n",
    "    \n",
    "# Projection of Matrices/Vectors for PCA\n",
    "![Projection Vector](vectors.png)\n",
    "1. vector(a) + vector(b) = vector(c)\n",
    "2. vector(a) = vector(p) + vector(e)\n",
    "    - Also vector(p) = L.vector(b)\n",
    "3. vector(e) = vector(a) - vector(p)\n",
    "    - Also vetcor(b) . vector(e) = 0 (e perp to b)\n",
    "4. vect(b) . (vect(a) - vect(p)) = 0\n",
    "5. vect(b) . (vect(a) - L.vetcor(b)) = 0\n",
    "6. vect(b) . vect(a) - L.vect(b) . vect(b) = 0\n",
    "7. L = ( vect(b) . vect(a) )/( vect(b) . vect(b) )\n",
    "8. L = ( vect(b) . vect(a) )/( |b|^2 )\n",
    "![Projection Vector](projVector.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA EXPLANATION\n",
    "![Ideal Covarinace Matrix](idealcov.png)\n",
    "1. Good Data features\n",
    "    - Covariance or Correlation between Features should be high\n",
    "    - Inter Feature cov/cor shuld be low\n",
    "    - individual feature var should be high\n",
    "2. X(our data old one) --- projection on [u1 u2] ---> X(ideal data)\n",
    "3. We have to project our data to new coordinate space where it behaves ideally\n",
    "4. Eigen Value Decomposition says:\n",
    "    - A(vector matrix) . Q = Q . L(sparse matrix)\n",
    "    - Q^-1 . A . Q = Q^-1 . Q . L\n",
    "    - Q^-1 . A . Q = L\n",
    "5. Q^-1(inv of eigen matrix) . X(cov matrix) . Q(eigen matrix) = X^ (ideal cov matrix which is also a sparse matrix)\n",
    "6. X(mxn) . Q(nxn) = X^(mxn)\n",
    "7. Eigen Vetor matrix (Q) has eigen values matrix also -- arranged in ascending order -- last column has high variance \n",
    "8. Convert Eigen matrix of nxn into nxn-10 (remove 10 features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Dataset\n",
    "- Here pixels of the images are the features\n",
    "- Ml algorithm fails for large number of dimensions so we use PCA algorithm to reduce the dimensionality \n",
    "- We use SVM Algorithm with PCA Algorithm in a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Barack Obama', 'Donald Trump', 'George W Bush']\n",
      "[0 1 2]\n",
      "{'Barack Obama': 0, 'Donald Trump': 1, 'George W Bush': 2}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "data_path=r'train_data_2' # name of folder in which training data is present\n",
    "\n",
    "labels=os.listdir(data_path) # To list out the names of folders present in that directory\n",
    "categories=np.arange(len(labels)) # To make a list of labels from 0 to number of folders present\n",
    "category_dict=dict(zip(labels,categories)) # To map the labels to the corrsponding tarinin data\n",
    "\n",
    "print(labels)\n",
    "print(categories)\n",
    "print(category_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "face_classifier=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "#classifier file -- \n",
    "\n",
    "data=[] # data list carries cropped images into 50 x 50\n",
    "target=[] # label of the cropped imaged\n",
    "\n",
    "for label in labels: # iterating through labels list\n",
    "     \n",
    "    imgs_path=os.path.join(data_path,label) # To the image path --> tarin_data_2/label_name\n",
    "    img_names=os.listdir(imgs_path)# extract the names of images in that folder\n",
    "    \n",
    "    for img_name in img_names:# loop through each and every image \n",
    "        \n",
    "        img_path=os.path.join(imgs_path,img_name) #to join the whole path--> train_data_2/label_name/image_name.png \n",
    "        img=cv2.imread(img_path) #loads the image into the code as an object\n",
    "    \n",
    "        # we can use cv2.imshow(img_path) --> to display every photo loaded as object\n",
    "        # cv2.waitKey(100) --> a delay of 100 mseconds between each photo transition\n",
    "        \n",
    "        gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) # convert the color image to grayscale image\n",
    "        faces=face_classifier.detectMultiScale(gray)# use the cascade classifier\n",
    "        \n",
    "        # draw rectangel -- cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2) -- (image,(Point 1),(Point 2),(Color of box),line thickness of box in pixels)\n",
    "        # It showa some false positives like bg of something and therefore we need to crop it\n",
    "        # we filter out of the images inside the boxes (faces and false positives)\n",
    "        \n",
    "        try:\n",
    "        \n",
    "            for (x,y,w,h) in faces: # looping in the faces that return the boxes we extract the x y w h features \n",
    "\n",
    "                cropped_face=gray[y:y+h,x:x+w] #\n",
    "                cv2.imshow('cropped_face',cropped_face)\n",
    "\n",
    "                print(\"If you accept this image press y else press n: \")\n",
    "                k=cv2.waitKey(0) # wait infinite times till key is pressed and then coninue storing the value of key\n",
    "\n",
    "                if(k==121): # if y is pressed\n",
    "                    cropped_face=cv2.resize(cropped_face,(50,50)) # resize the image into 50 x 50 and save it as a data\n",
    "                    data.append(cropped_face)# cropped images data\n",
    "                    target.append(category_dict[label])# cropped images label\n",
    "                    \n",
    "                else:\n",
    "                    pass       \n",
    "        except:\n",
    "            pass\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.array(data) # making a numpy array\n",
    "data=data.reshape(data.shape[0],data.shape[1]*data.shape[2]) # converting into data_rows(258 pictures) x data_columns(2500 pixels/feature coulmuns)\n",
    "target=np.array(target)# making a array of 258 labels of each image\n",
    "\n",
    "np.save('data',data) # saving it as a numpy array physical file\n",
    "np.save('target',target) # saving it as a numpy array physical file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Dataset on SVM Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data=np.load('data.npy')\n",
    "target=np.load('target.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(285, 2500)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### We have 285 values and 2500 features/coulmns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(285,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC #importing the SVM\n",
    "from sklearn.decomposition import PCA #importing PCA\n",
    "from sklearn.pipeline import make_pipeline # To combine 2 algorithms\n",
    "\n",
    "pca=PCA(n_components=150,whiten=True,random_state=42)\n",
    "svc=SVC(kernel='rbf') # We use Radial Bias Function\n",
    "\n",
    "model=make_pipeline(pca,svc)# [PCA --> 150 features --> SVM] -- PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Split the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data,test_data,train_target,test_target=train_test_split(data,target,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('pca', PCA(n_components=150, random_state=42, whiten=True)),\n",
       "                ('svc', SVC())])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data,train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_target=model.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the Accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9655172413793104\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc=accuracy_score(test_target,predicted_target)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      " Barack Obama       0.89      1.00      0.94         8\n",
      " Donald Trump       1.00      0.93      0.96        14\n",
      "George W Bush       1.00      1.00      1.00         7\n",
      "\n",
      "     accuracy                           0.97        29\n",
      "    macro avg       0.96      0.98      0.97        29\n",
      " weighted avg       0.97      0.97      0.97        29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(test_target,predicted_target,target_names=['Barack Obama', 'Donald Trump', 'George W Bush']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting the trained model into the Physical file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SVM-Face Recognition.sav']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model,'SVM-Face Recognition.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "model=joblib.load('SVM-Face Recognition.sav') # Load the tarined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_dict={0:'Barack Obama', 1:'Donald Trump',2:'George W Bush'} # use the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['barack-obama-12782369-1-402.jpg', 'barack-obama.jpeg', 'https___d1e00ek4ebabms.cloudfront.net_production_b8c5ac6e-d1ec-467a-b185-a5c7b2fc1c9b.jpg', 'president-george-w-bush-listens-to-a-question-during-a-news-news-photo-1591807580.jpg', 'screen_shot_2020-06-07_at_9.28.05_am.png', 'trump.jpg']\n"
     ]
    }
   ],
   "source": [
    "test_data_path='test_data' # Test Data path\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "face_classifier=cv2.CascadeClassifier('haarcascade_frontalface_default.xml') # Cascade Classifier\n",
    "\n",
    "test_img_names=os.listdir(test_data_path)# Get all the test images names\n",
    "print(test_img_names)\n",
    "\n",
    "for test_img in test_img_names:\n",
    "    img_path=os.path.join(test_data_path,test_img) # test image path\n",
    "    test_img=cv2.imread(img_path) # read the test images\n",
    "    \n",
    "    gray=cv2.cvtColor(test_img,cv2.COLOR_BGR2GRAY) # convert it to gray color\n",
    "    \n",
    "    faces=face_classifier.detectMultiScale(gray) # detect faces \n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        \n",
    "        cv2.rectangle(test_img,(x,y),(x+w,y+h),(0,255,0),2) # draw a box\n",
    "        \n",
    "        cropped_face=gray[y:y+h,x:x+w] # crop out the box \n",
    "        cropped_face=cv2.resize(cropped_face,(50, 50)) # resize the cropped image into 50 by 50 \n",
    "        cropped_original=cropped_face\n",
    "        cropped_face=cropped_face.reshape(1,50*50)# flatten the cropped image into 2500 features\n",
    "        \n",
    "        result=model.predict(cropped_face) # model will predict into labels 0/1/2 values\n",
    "        name=category_dict[result[0]] # take the value(result) and then \n",
    "\n",
    "        cv2.putText(test_img,name,(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,1.5,(0,255,0),2) # we put a name tag just 10 pixels above y value\n",
    "        #cv2.imshow('GRAY',cropped_original) # show the grayscale cropped image -- TESTING PURPOSES\n",
    "    cv2.imshow('LIVE',test_img)\n",
    "    \n",
    "    \n",
    "    k=cv2.waitKey(1000)\n",
    "    if(k==27):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- source = cv2.VideoCaptaure(0) # 0 for web camera -- 1 for usb camera -- two usb camera then 2\n",
    "- source = cv2.VideoCaptaurefile_path) # video file path\n",
    "- while(true)\n",
    "    - ret,img = source.read() # read continous frames\n",
    "    - k = cv2.key(10) # 10 milisec for reading"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
